name: scrape
on:
  [push]
  workflow_dispatch:
  schedule:
    - cron: '*/30 * * * *'
jobs:
  scrape:
    runs-on: ubuntu-latest
    steps: 
      - name: Check out this repo
        uses: actions/checkout@v2
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.9'
      - name: Install the necessary libraries
        run: pip install requests beautifulsoup4 pandas
      - name: Run our scraping script
        run: python lenta_scraper.py
      - name: Commit and push if content changed
        run: |-
          git config user.name "Automated"
          git config user.email "actions@users.noreply.github.com"
          git add -A
          timestamp=$(date -u)
          git commit -m "Latest data: ${timestamp}" || exit 0
          git push
      - name: Commit and push and email if content changed
        env:
          SENDGRID_API_KEY: ${{ secrets.SENDGRID_API_KEY }}
          FROM_EMAIL: ${{ secrets.FROM_EMAIL }}
          TO_EMAIL: ${{ secrets.TO_EMAIL }}
        run: |-
          git config user.name "Automated"
          git config user.email "actions@users.noreply.github.com"
          git add -A
          timestamp=$(date -u)
          git commit -m "Latest data: ${timestamp}" &&
            python lenta_scraper.py ||
            exit 0
          git push